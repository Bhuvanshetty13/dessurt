{
    "name": "iamRecog_mmswin_bart_PTfrom275ilatest_297",
    "cuda": true,
    "gpu": 0,
    "save_mode": "state_dict",
    "override": true,
    "data_loader": {
        "data_set_name": "IAMQA",
        "data_dir": "../data/IAM",
        "cased": true,
        "mode": "IAM_para",
        "data_split": "Coquenet",
        "batch_size": 1,
        "num_workers": 6,
        "shuffle": true,
        "persistent_workers": true,
        "rescale_range": [
            0.6,
            1
        ],
        "rescale_to_crop_size_first": true,
        "crop_params": {
            "crop_size": [
                1152,
                768
            ],
            "pad": 0,
            "rot_degree_std_dev": 1
        },
        "questions": 1,
        "max_qa_len": 220000
    },
    "validation": {
        "shuffle": false,
        "batch_size": 3,
        "rescale_range": [
            0.9,
            0.9
        ],
        "crop_params": {
            "crop_size": [
                1152,
                768
            ],
            "pad": 0,
            "random": false
        }
    },
    "lr_scheduler_type": "none",
    "optimizer_type": "AdamW",
    "optimizer": {
        "lr": 0.0001,
        "weight_decay": 0.01
    },
    "loss": {
        "#answer": "padded_seq_cross_entropy",
        "answer": "label_smoothing",
        "#mask": "sigmoid_BCE_mask_loss",
        "mask": "focalLoss"
    },
    "loss_weights": {
        "answer": 1,
        "mask": 1,
        "cosine": 0,
        "distillation": 2.5
    },
    "loss_params": {
        "xanswer": {},
        "answer": {
            "smoothing": 0.1,
            "padding_idx": 1
        }
    },
    "metrics": [],
    "trainer": {
        "class": "QATrainer",
        "iterations": 91200,
        "accum_grad_steps": 64,
        "#swa": true,
        "#swa_start": 200000,
        "save_dir": "saved/",
        "val_step": 10000,
        "save_step": 1400000000,
        "save_step_minor": 1024,
        "log_step": 1024,
        "print_pred_every": 1024,
        "verbosity": 1,
        "monitor": "val_read_block>_ED",
        "monitor_mode": "min",
        "retry_count": 0,
        "do_ocr": "no",
        "#use_learning_schedule": "multi_rise then ramp_to_swa",
        "use_learning_schedule": "multi_rise then ramp_to_lower",
        "warmup_steps": [
            1000
        ],
        "lr_down_start": 60000,
        "ramp_down_steps": 10000,
        "lr_mul": 0.1
    },
    "arch": "MmSwin",
    "model": {
        "image_size": [
            1152,
            768
        ],
        "use_set_length": true,
        "init_from_pretrained": "bart",
        "use_special_question_tokens": true,
        "max_q_tokens": 20,
        "#max_a_tokens": 3400,
        "max_a_tokens": 730,
        "no_dropout": false,
        "window_size": 12,
        "decode_dim": 768,
        "dim_ff": 3072,
        "decode_num_heads": 8,
        "blocks_per_level": [
            4,
            6
        ],
        "use_swin": [
            true,
            true,
            true,
            true,
            true,
            true,
            true,
            true,
            false,
            false
        ],
        "swin_cross_attention": [
            true,
            true,
            true,
            true,
            true,
            true,
            true,
            true,
            false,
            false
        ],
        "swin_nheads": [
            4,
            8
        ],
        "im_embed_dim": 128
    }
}